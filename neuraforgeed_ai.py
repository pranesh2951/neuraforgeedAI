# -*- coding: utf-8 -*-
"""neuraforgeed_AI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16KMH3nNohVIxT-VLEwOjf7JF3pDo7DQs
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

# ğŸ“Œ STEP 1: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# ğŸ“Œ STEP 2: Set folder paths
import os
pdf_folder = '/content/drive/MyDrive/aerospace_engineering'  # ğŸ” Folder with PDFs
model_path = '/content/drive/MyDrive/neuraforgeed_model.pth'  # ğŸ” Save trained model here

# ğŸ“Œ STEP 3: Install PDF parser
!pip install -q pdfplumber

# ğŸ“Œ STEP 4: Extract text from all PDFs
import pdfplumber

def extract_text_from_pdf(pdf_path):
    text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    return text

pdf_data = {}
for filename in os.listdir(pdf_folder):
    if filename.endswith(".pdf"):
        full_path = os.path.join(pdf_folder, filename)
        try:
            content = extract_text_from_pdf(full_path)
            pdf_data[filename] = content
            print(f"ğŸ“– Loaded: {filename}")
        except Exception as e:
            print(f"âš ï¸ Error reading {filename}: {e}")

# ğŸ“Œ STEP 5: Define your AI model
import torch
import torch.nn as nn
import torch.nn.functional as F

class neuraforgeed(nn.Module):
    def __init__(self):
        super(neuraforgeed, self).__init__()
        self.career_encoder = nn.Linear(10, 16)
        self.pace_encoder = nn.Linear(5, 8)
        self.weakness_encoder = nn.Linear(5, 8)
        self.feedback_encoder = nn.Linear(3, 8)
        self.user_encoder = nn.Linear(6, 8)
        self.embedding = nn.Linear(48, 64)
        self.hidden1 = nn.Linear(64, 64)
        self.hidden2 = nn.Linear(64, 64)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.3)
        self.course_head = nn.Linear(32, 3)
        self.style_head = nn.Linear(32, 2)
        self.cert_head = nn.Linear(32, 1)
        self.referral_head = nn.Linear(32, 1)
        self.reasoning_head = nn.Linear(32, 2)
        self.confidence_head = nn.Linear(32, 1)

    def forward(self, career, pace, weakness, feedback, user_profile):
        c = self.career_encoder(career)
        p = self.pace_encoder(pace)
        w = self.weakness_encoder(weakness)
        f = self.feedback_encoder(feedback)
        u = self.user_encoder(user_profile)
        x = torch.cat([c, p, w, f, u], dim=1)
        x = self.embedding(x)
        x = self.relu(x)
        x = self.hidden1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.hidden2(x)
        x = self.relu(x)
        shared = x[:, :32]
        return {
            "course": self.course_head(shared),
            "style": self.style_head(shared),
            "cert": self.cert_head(shared),
            "referral": self.referral_head(shared),
            "reasoning": self.reasoning_head(shared),
            "confidence": self.confidence_head(shared)
        }

# ğŸ“Œ NEW: Smarter signal extractor
def extract_training_signal(text):
    objectives = text.count("Objective")
    quizzes = text.count("Quiz")
    equations = text.count("=")
    diagrams = text.count("Diagram")
    score = objectives + quizzes + equations + diagrams
    return min(score / 20, 1.0)  # Normalize and cap at 1.0

# ğŸ“Œ STEP 6: Auto-train using smarter signal from PDFs
model = neuraforgeed()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
loss_fn = nn.MSELoss()

for epoch in range(10):  # ğŸ” Adjust epochs as needed
    for name, text in pdf_data.items():
        signal = extract_training_signal(text)
        target = torch.tensor([[signal]], dtype=torch.float32)

        career_input = torch.randn(1, 10)
        pace_input = torch.randn(1, 5)
        weakness_input = torch.randn(1, 5)
        feedback = torch.randn(1, 3)
        user_profile = torch.randn(1, 6)

        output = model(career_input, pace_input, weakness_input, feedback, user_profile)
        cert_output = output["cert"]
        loss = loss_fn(cert_output, target)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        print(f"ğŸ§  Epoch {epoch+1} | {name} | Signal: {signal:.2f} | Loss: {loss.item():.4f}")

# ğŸ“Œ STEP 7: Save trained model
torch.save(model.state_dict(), model_path)
print(f"âœ… Model saved to: {model_path}")

class neuraforgeed(nn.Module):
    def __init__(self):
        super(neuraforgeed, self).__init__()

        # Input encoders
        self.career_encoder = nn.Linear(10, 16)
        self.pace_encoder = nn.Linear(5, 8)
        self.weakness_encoder = nn.Linear(5, 8)
        self.feedback_encoder = nn.Linear(3, 8)
        self.user_encoder = nn.Linear(6, 8)

        # Core layers
        self.embedding = nn.Linear(48, 64)
        self.hidden1 = nn.Linear(64, 64)
        self.hidden2 = nn.Linear(64, 64)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.3)

        # Output heads
        self.course_head = nn.Linear(32, 3)
        self.style_head = nn.Linear(32, 2)
        self.cert_head = nn.Linear(32, 1)
        self.referral_head = nn.Linear(32, 1)
        self.reasoning_head = nn.Linear(32, 2)
        self.confidence_head = nn.Linear(32, 1)

    def forward(self, career, pace, weakness, feedback, user_profile):
        # Encode inputs
        c = self.career_encoder(career)
        p = self.pace_encoder(pace)
        w = self.weakness_encoder(weakness)
        f = self.feedback_encoder(feedback)
        u = self.user_encoder(user_profile)

        # Combine
        x = torch.cat([c, p, w, f, u], dim=1)
        x = self.embedding(x)
        x = self.relu(x)
        x = self.hidden1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.hidden2(x)
        x = self.relu(x)

        # Split into heads
        shared = x[:, :32]
        return {
            "course": self.course_head(shared),
            "style": self.style_head(shared),
            "cert": self.cert_head(shared),
            "referral": self.referral_head(shared),
            "reasoning": self.reasoning_head(shared),
            "confidence": self.confidence_head(shared)
        }

model = neuraforgeed()                        # Instantiate upgraded model

# Create dummy inputs for each stream
career_input = torch.randn(1, 10)               # Career goals
pace_input = torch.randn(1, 5)                  # Learning speed
weakness_input = torch.randn(1, 5)              # Weak areas
feedback = torch.randn(1, 3)
user_profile = torch.randn(1, 6)
# Run forward pass
output = model(career_input, pace_input, weakness_input,feedback,user_profile)

# Print each output head
print("Course Recommendations:", output["course"])
print("Teaching Style:", output["style"])
print("Certificate Readiness:", output["cert"])
print("Referral Score:", output["referral"])

model = neuraforgeed()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
loss_fn = nn.MSELoss()

for epoch in range(100):
    # ğŸ”¹ Generate dummy inputs
    career_input = torch.randn(1, 10)
    pace_input = torch.randn(1, 5)
    weakness_input = torch.randn(1, 5)
    feedback = torch.randn(1, 3)
    user_profile = torch.randn(1, 6)


    # ğŸ”¹ Target for one output head (e.g., certificate readiness)
    target = torch.tensor([[0.5]])

    # ğŸ”¹ Forward pass
    output = model(career_input, pace_input, weakness_input,feedback,user_profile)

    # ğŸ”¹ Select the head to train (e.g., "cert")
    cert_output = output["cert"]

    # ğŸ”¹ Compute loss
    loss = loss_fn(cert_output, target)

    # ğŸ”¹ Backpropagation
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()

    # ğŸ”¹ Optional: print progress
    print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

def ask_model(career_list, pace_list, weakness_list, feedback, user_profile, head="cert"):
    # Convert lists to tensors
    career_tensor = torch.tensor([career_list], dtype=torch.float32)
    pace_tensor = torch.tensor([pace_list], dtype=torch.float32)
    weakness_tensor = torch.tensor([weakness_list], dtype=torch.float32)
    feedback_tensor = torch.tensor([feedback], dtype=torch.float32)
    user_tensor = torch.tensor([user_profile], dtype=torch.float32)

    # Run model in inference mode
    with torch.no_grad():
        output = model(career_tensor, pace_tensor, weakness_tensor, feedback_tensor, user_tensor)

    # Return selected output head
    result = output[head]
    if result.numel() == 1:
        return result.item()
    else:
        return result.squeeze().tolist()

career_list = [0.2] * 10
pace_list = [0.5] * 5
weakness_list = [0.1] * 5
feedback = [0.3] * 3         # âœ… Correct size
user_profile = [0.4] * 6     # âœ… Correct size

score = ask_model(career_list, pace_list, weakness_list, feedback, user_profile, head="cert")
print("Certificate Readiness Score:", score)

import os
from google.colab import drive

# Mount only if not already mounted
if not os.path.exists('/content/drive/MyDrive'):
    drive.mount('/content/drive')

# Save model
torch.save(model.state_dict(), '/content/drive/MyDrive/neuraforgeed_model.pth')

model = neuraforgeed()
model.load_state_dict(torch.load('/content/drive/MyDrive/neuraforgeed_model.pth'))
model.eval()

career_input = torch.tensor([[0.9]*10])  # Aerospace-heavy
pace_input = torch.tensor([[0.5]*5])     # Medium pace
weakness_input = torch.tensor([[0.1]*5]) # Strong in topic
feedback = torch.tensor([[0.3]*3])       # Moderate feedback
user_profile = torch.tensor([[0.7]*6])   # Advanced learner

output = model(career_input, pace_input, weakness_input, feedback, user_profile)

print("ğŸ“˜ Course Recommendation:", output["course"].detach().numpy())
print("ğŸ“ Certificate Readiness:", output["cert"].item())
print("ğŸ§  Confidence:", output["confidence"].item())
print("ğŸ§© Reasoning:", output["reasoning"].detach().numpy())

course_labels = ["Aerodynamics", "Propulsion", "Structures"]
course_scores = output["course"].detach().numpy()[0]
recommended_course = course_labels[course_scores.argmax()]
cert_score = output["cert"].item()
confidence_score = output["confidence"].item()
reasoning_vector = output["reasoning"].detach().numpy()[0]

print(f"ğŸ“˜ Recommended Course: {recommended_course}")
print(f"ğŸ“ Certificate Readiness: {cert_score:.2f} / 1.00")
print(f"ğŸ§  Confidence Level: {confidence_score:.2f}")
print(f"ğŸ§© Reasoning Trace: {reasoning_vector}")

# Propulsion question
output2 = model(torch.tensor([[0.9]*10]), torch.tensor([[0.5]*5]), torch.tensor([[0.3]*5]), torch.tensor([[0.2]*3]), torch.tensor([[0.7]*6]))

# Structures question
output3 = model(torch.tensor([[0.6]*10]), torch.tensor([[0.3]*5]), torch.tensor([[0.4]*5]), torch.tensor([[0.4]*3]), torch.tensor([[0.5]*6]))

def readable_output(output, label):
    course_labels = ["Aerodynamics", "Propulsion", "Structures"]
    course_scores = output["course"].detach().numpy()[0]
    recommended_course = course_labels[course_scores.argmax()]
    cert_score = output["cert"].item()
    confidence_score = output["confidence"].item()
    print(f"\nğŸ” {label}")
    print(f"ğŸ“˜ Recommended Course: {recommended_course}")
    print(f"ğŸ“ Certificate Readiness: {cert_score:.2f}")
    print(f"ğŸ§  Confidence Level: {confidence_score:.2f}")

#readable_output(output1, "Reynolds Number")
readable_output(output2, "Thrust Equation")
readable_output(output3, "Stress Distribution")